<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Monitoring and Distributed Tracing with Grafana, Prometheus, Loki & Tempo &#183; Cozi</title><meta name=description content><link rel=stylesheet href=/scss/main.min.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&family=Montserrat:wght@500;600;700;800&family=JetBrains+Mono:wght@400;500&display=swap" rel=stylesheet><script src=/js/main.min.js defer></script><meta property="og:title" content="Monitoring and Distributed Tracing with Grafana, Prometheus, Loki & Tempo"><meta property="og:description" content="Why I Built a Small Observability Stack Over the last few years, my systems have become more distributed: multiple services, containers, and external dependencies all talking to each other."><meta property="og:type" content="article"><meta property="og:url" content="https://cozi.dev/posts/monitoring-and-distributed-tracing-with-grafana-prometheus-loki-and-tempo/"><meta property="article:published_time" content="2025-12-01T11:34:20+07:00"><meta property="article:modified_time" content="2025-12-01T11:34:20+07:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Monitoring and Distributed Tracing with Grafana, Prometheus, Loki & Tempo"><meta name=twitter:description content="Why I Built a Small Observability Stack Over the last few years, my systems have become more distributed: multiple services, containers, and external dependencies all talking to each other."><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest></head><body><header class=site-header><div class=header-content><div class=nav-wrapper><div class=site-title><a href=https://cozi.dev/ class=logo-container><img class=logo src=https://cozi.dev/images/logo_light.svg title=Cozi alt=Cozi></a></div><nav class=main-nav><ul><li><a href=/about/>About</a></li><li><a href=/posts/>Posts</a></li><li><a href=/tags/>Tags</a></li><li><a href=/portfolio/>Portfolio</a></li><li><a href=/archives/>Archives</a></li><li><a href=/hire-me/>Hire me</a></li><li><button id=theme-toggle class=theme-toggle aria-label="Toggle dark mode"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></button></li></ul></nav></div><button id=mobile-menu-toggle class=mobile-menu-toggle aria-label="Toggle menu" aria-expanded=false><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button></div></header><div class=container><main class=main><div class=content><h1 class=post-title>Monitoring and Distributed Tracing with Grafana, Prometheus, Loki & Tempo</h1><time>December 1, 2025</time><div class="toc top"><small>8 mins read</small><h6 class=toc-label>What's on this page</h6><div class=toc-body><nav id=TableOfContents><ul><li><a href=#why-i-built-a-small-observability-stack>Why I Built a Small Observability Stack</a></li><li><a href=#highlevel-goals>High‑Level Goals</a></li><li><a href=#stack-overview>Stack Overview</a></li><li><a href=#data-flow-metrics>Data Flow: Metrics</a></li><li><a href=#data-flow-logs>Data Flow: Logs</a></li><li><a href=#data-flow-traces>Data Flow: Traces</a></li><li><a href=#a-typical-developer-workflow>A Typical Developer Workflow</a></li><li><a href=#running-the-demo-locally>Running the Demo Locally</a></li><li><a href=#next-steps-and-ideas>Next Steps and Ideas</a></li></ul></nav></div></div><div class=post-content><p><h2 id=why-i-built-a-small-observability-stack>Why I Built a Small Observability Stack</h2><img class=article-image src=/posts/monitoring-and-distributed-tracing-with-grafana-prometheus-loki-and-tempo/overview.jpg alt><p>Over the last few years, my systems have become more <strong>distributed</strong>: multiple services, containers, and external dependencies all talking to each other. When something breaks in that world, traditional monitoring (CPU, memory, a handful of logs on a single box) doesn’t give enough context to answer the real questions:</p><ul><li><strong>What exactly is broken?</strong></li><li><strong>Where in the request path is it failing or slowing down?</strong></li><li><strong>How do logs, metrics and traces relate to each other?</strong></li></ul><p>To explore better answers, I put together a small end‑to‑end demo stack using <strong>Prometheus, Loki, Tempo and Grafana</strong>, plus a couple of example services (Go and Rust) that emit logs, metrics and traces. The source code is available here: <a href=https://github.com/cozi-dev/monitoring-stack>cozi-dev/monitoring-stack</a>.</p><p>This post is a walkthrough of that stack and how I use it day‑to‑day as a developer.</p><h2 id=highlevel-goals>High‑Level Goals</h2><p>The idea is not to build a “perfect” production setup, but a minimal playground that lets me:</p><ul><li><strong>See system health</strong> via metrics</li><li><strong>Understand behaviour</strong> via logs</li><li><strong>Trace requests end‑to‑end</strong> across services</li></ul><p>If you want a concrete way to <em>feel</em> what observability gives you (instead of just reading theory), spinning up this stack locally is a great starting point.</p><h2 id=stack-overview>Stack Overview</h2><p>At a high level, the demo includes:</p><ul><li><strong>Example services (Go, Rust, etc.)</strong><ul><li>Expose HTTP <strong><code>/metrics</code></strong> endpoints for Prometheus.</li><li>Write <strong>logs</strong> to stdout.</li><li>Emit <strong>distributed traces</strong> via OpenTelemetry.</li></ul></li></ul><ul><li><strong>cAdvisor</strong><ul><li>Runs as a container on the host.</li><li>Collects CPU, memory, filesystem and network metrics for each container and the host.</li><li>Exposes a Prometheus‑compatible metrics endpoint.</li></ul></li></ul><ul><li><strong>Prometheus</strong><ul><li>Scrapes metrics from the services and from cAdvisor.</li><li>Stores time‑series data and powers metric queries and alerts.</li></ul></li></ul><ul><li><strong>Promtail</strong><ul><li>Tails Docker container logs.</li><li>Enriches them with labels (service, container, environment, etc.).</li><li>Ships everything to Loki.</li></ul></li></ul><ul><li><strong>Loki</strong><ul><li>Stores log streams indexed by <strong>labels</strong> instead of full‑text.</li><li>Optimised for cheap log storage and fast queries in Grafana.</li></ul></li></ul><ul><li><strong>Tempo</strong><ul><li>Receives and stores <strong>traces</strong> (groups of spans) from the services.</li><li>Lets you search and inspect traces via Grafana.</li></ul></li></ul><ul><li><strong>Grafana</strong><ul><li>The single UI that connects to <strong>Prometheus (metrics)</strong>, <strong>Loki (logs)</strong> and <strong>Tempo (traces)</strong>.</li><li>Provides dashboards, logs exploration, and trace visualisation.</li><li>Makes it easy to jump between <strong>metrics ↔ logs ↔ traces</strong> during an investigation.</li></ul></li></ul><p>From a developer point of view, Grafana becomes the “home base” for understanding how the whole system behaves.</p><h2 id=data-flow-metrics>Data Flow: Metrics</h2><p>For metrics, the flow looks like this:</p><ul><li><strong>Services and cAdvisor expose metrics endpoints</strong><ul><li>Application services expose <code>/metrics</code> with counters, histograms, etc.</li><li>cAdvisor exposes container and host metrics (CPU, memory, disk, network).</li></ul></li></ul><ul><li><strong>Prometheus scrapes on a schedule</strong><ul><li>Periodically hits those endpoints.</li><li>Stores time‑series such as request rate, error rate, and latency percentiles.</li></ul></li></ul><ul><li><strong>Grafana visualises</strong><ul><li>Using the Prometheus data source, I build panels like:<ul><li><strong>Request rate (RPS)</strong> per service</li><li><strong>Error rate</strong> (4xx/5xx)</li><li><strong>Latency</strong> (p50, p95, p99)</li><li><strong>Container/host resource usage</strong> (from cAdvisor)</li></ul></li></ul></li></ul><p>This gives us the classic SRE‑style view: how fast, how often, and how broken things are.</p><img class=article-image src=/posts/monitoring-and-distributed-tracing-with-grafana-prometheus-loki-and-tempo/metrics1.png alt>
<img class=article-image src=/posts/monitoring-and-distributed-tracing-with-grafana-prometheus-loki-and-tempo/metrics2.png alt><h2 id=data-flow-logs>Data Flow: Logs</h2><p>Logs are still the best way to understand <strong>what</strong> a service thought it was doing at a specific moment. In this stack:</p><ul><li><strong>Services log to stdout/stderr</strong><ul><li>No log files, just container logs.</li></ul></li></ul><ul><li><strong>Docker captures container logs</strong><ul><li>Standard Docker logging mechanism.</li></ul></li></ul><ul><li><strong>Promtail tails Docker logs</strong><ul><li>Reads logs from Docker.</li><li>Attaches labels like service name, container, environment.</li><li>Sends everything to <strong>Loki</strong>.</li></ul></li></ul><ul><li><strong>Loki stores log streams by labels</strong><ul><li>Instead of indexing the entire log body, it focuses on labels.</li><li>That’s why Loki is a good fit for high‑volume, low‑cost logging.</li></ul></li></ul><ul><li><strong>Grafana queries Loki</strong><ul><li>In the Explore view, I can filter logs by:<ul><li><strong>Service</strong> (e.g. <code>service="payments"</code>)</li><li><strong>HTTP status</strong> or path</li><li>Correlation IDs</li></ul></li></ul></li></ul><p>Once you get used to label‑based log queries, it becomes very natural to drill into just the context you care about.</p><img class=article-image src=/posts/monitoring-and-distributed-tracing-with-grafana-prometheus-loki-and-tempo/log.png alt><h2 id=data-flow-traces>Data Flow: Traces</h2><p>Even with good metrics and logs, it can still be hard to see how a single user request flows across many services. That’s where <strong>tracing</strong> comes in:</p><ul><li><strong>Services are instrumented with OpenTelemetry</strong><ul><li>Each incoming request creates a <strong>root span</strong>.</li><li>Downstream calls (DB queries, HTTP calls to other services, etc.) create child spans.</li></ul></li></ul><ul><li><strong>Spans are sent to Tempo</strong><ul><li>Tempo groups spans into a <strong>trace</strong> that represents the whole request path.</li></ul></li></ul><ul><li><strong>Grafana visualises traces</strong><ul><li>With the Tempo data source, I can:<ul><li>Search traces by service, operation or duration.</li><li>See a waterfall view of where latency is introduced.</li><li>Spot failing segments immediately.</li></ul></li></ul></li></ul><p>Traces are especially powerful when you have intermittent or high‑latency issues: they tell you exactly which segment of the request path misbehaved.</p><img class=article-image src=/posts/monitoring-and-distributed-tracing-with-grafana-prometheus-loki-and-tempo/trace.png alt><h2 id=a-typical-developer-workflow>A Typical Developer Workflow</h2><p>Here’s a realistic workflow I use with this stack:</p><ol><li><strong>Notice a spike in errors in metrics</strong><ul><li>In a Prometheus‑backed Grafana dashboard, I see a panel where <code>http_requests_total{status="5xx"}</code> suddenly jumps for one service.</li></ul></li><li><strong>Zoom into the problematic time window</strong><ul><li>Narrow the time range around the spike.</li></ul></li><li><strong>Pivot to logs (Loki)</strong><ul><li>In Grafana Explore, switch the data source to Loki but keep the same time range.</li><li>Filter logs by service name and maybe error fields or correlation IDs.</li><li>Read the actual error messages.</li></ul></li><li><strong>Jump into traces (Tempo)</strong><ul><li>From the same context, open the Tempo data source.</li><li>Search for long‑running or errored traces in that time window.</li><li>Inspect the slow spans and see which dependency is causing trouble.</li></ul></li><li><strong>Loop back to code</strong><ul><li>Now I know which service, which endpoint, and which downstream call is responsible, and I can go fix it in code.</li></ul></li></ol><p>This tight <strong>metrics → logs → traces</strong> loop is the main reason I like this stack. It dramatically reduces the “guessing” phase of debugging.</p><h2 id=running-the-demo-locally>Running the Demo Locally</h2><p>If you want to try this yourself, you only need <strong>Docker</strong> and <strong>Docker Compose</strong>.</p><p>Clone the repository:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>git clone https://github.com/cozi-dev/monitoring-stack.git
cd monitoring-stack
</code></pre></div><p>Start the whole stack:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>docker-compose up -d
</code></pre></div><p>Once the containers are up:</p><ul><li><strong>Grafana UI</strong>: <code>http://localhost:13000</code></li><li>Default login: <code>admin</code> / <code>admin</code> (or whatever you configure)</li><li>Preconfigured data sources: <strong>Prometheus</strong>, <strong>Loki</strong>, <strong>Tempo</strong></li></ul><p>From there you can:</p><ul><li><strong>Open metrics dashboards</strong> and watch traffic, errors and latency.</li><li><strong>Query logs</strong> from any service with labels in Loki.</li><li><strong>Explore traces</strong> in Tempo and understand full request paths.</li></ul><p>Feel free to break the example services on purpose (add artificial latency, return 500s, etc.) and then use the stack to trace what happened.</p><h2 id=next-steps-and-ideas>Next Steps and Ideas</h2><p>This demo is intentionally minimal, but it’s close to what you would run in a real environment. Some natural next steps:</p><ul><li><strong>Create richer dashboards and alerts</strong> tailored to your domain (<a href=https://grafana.com/grafana/dashboards/>Grafana dashboards gallery</a>).</li><li><strong>Link advanced metrics to traces</strong> for better correlation (<a href="https://www.youtube.com/watch?v=TkapvLeMMpc">example talk</a>).</li><li><strong>Experiment with OpenTelemetry auto‑instrumentation</strong> for your language (<a href=https://opentelemetry.io/docs/zero-code/>OpenTelemetry zero‑code docs</a>).</li><li><strong>Apply this stack to Kubernetes</strong> instead of just Docker Compose.</li></ul><p>If you’re curious about observability but don’t know where to start, I hope this small stack (and the <a href=https://github.com/cozi-dev/monitoring-stack>monitoring-stack repo</a>) gives you something concrete to play with and adapt to your own systems.</p></p></div><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return;}
var d=document,s=d.createElement('script');s.async=true;s.src='//'+"cozi-dev"+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a><div class=page-footer><hr class=footer-divider><a class=tag href=/tags/monitoring>#monitoring</a>
<a class=tag href=/tags/distributed-tracing>#distributed-tracing</a>
<a class=tag href=/tags/grafana>#grafana</a>
<a class=tag href=/tags/prometheus>#prometheus</a>
<a class=tag href=/tags/loki>#loki</a>
<a class=tag href=/tags/tempo>#tempo</a></div></div><aside class=sidebar><div class=sidebar-section><h2 class=sidebar-heading>About</h2><p>Cozi is a place where I share my software development journey, exploring programming languages, frameworks, design patterns, and more.</p></div><div class=sidebar-section><h2 class=sidebar-heading>Recent Posts</h2><div class=recent-posts><div class=recent-post><a href=/posts/monitoring-and-distributed-tracing-with-grafana-prometheus-loki-and-tempo/>Monitoring and Distributed Tracing with Grafana, Prometheus, Loki & Tempo</a>
<span class=recent-post-date>Dec 1, 2025</span></div><div class=recent-post><a href=/posts/serving-aws-s3-private-content-with-golang-and-aws-sdk-for-go-v2/>Serving AWS S3 private content with Golang and AWS SDK for Go v2</a>
<span class=recent-post-date>Feb 5, 2024</span></div><div class=recent-post><a href=/posts/setting-up-a-virtual-environment-with-vagrant-for-testing/>Setting up a virtual environment with Vagrant for testing</a>
<span class=recent-post-date>Oct 11, 2023</span></div><div class=recent-post><a href=/posts/golang-create-combinations-from-n-arrays/>Golang Create Combinations From N Arrays</a>
<span class=recent-post-date>Sep 24, 2022</span></div><div class=recent-post><a href=/posts/mongodb-query-get-n-records-of-each-group-aggregation/>MongoDB query get n records of each group (aggregation)</a>
<span class=recent-post-date>Jul 4, 2022</span></div></div></div><div class=sidebar-section><h2 class=sidebar-heading>Tags</h2><div class=tags><a href=/tags/announcement class=tag>announcement (1)</a>
<a href=/tags/ansible class=tag>ansible (3)</a>
<a href=/tags/api class=tag>api (1)</a>
<a href=/tags/application class=tag>application (1)</a>
<a href=/tags/aws class=tag>aws (1)</a>
<a href=/tags/channels class=tag>channels (1)</a>
<a href=/tags/chat class=tag>chat (1)</a>
<a href=/tags/ci/cd class=tag>ci/cd (1)</a>
<a href=/tags/cicd class=tag>cicd (1)</a>
<a href=/tags/cli class=tag>cli (1)</a>
<a href=/tags/combination class=tag>combination (1)</a>
<a href=/tags/command class=tag>command (1)</a>
<a href=/tags/component class=tag>component (1)</a>
<a href=/tags/css class=tag>css (3)</a>
<a href=/tags/darkmode class=tag>darkmode (1)</a>
<a href=/tags/database class=tag>database (2)</a>
<a href=/tags/debug class=tag>debug (1)</a>
<a href=/tags/deployment class=tag>deployment (1)</a>
<a href=/tags/devops class=tag>devops (2)</a>
<a href=/tags/disk class=tag>disk (1)</a>
<a href=/tags/distributed-tracing class=tag>distributed-tracing (1)</a>
<a href=/tags/django class=tag>django (1)</a>
<a href=/tags/docker class=tag>docker (2)</a>
<a href=/tags/driver class=tag>driver (1)</a>
<a href=/tags/drone class=tag>drone (1)</a>
<a href=/tags/echo class=tag>echo (2)</a>
<a href=/tags/framework class=tag>framework (1)</a>
<a href=/tags/git class=tag>git (1)</a>
<a href=/tags/gitlab class=tag>gitlab (1)</a>
<a href=/tags/go class=tag>go (8)</a>
<a href=/tags/go-micro class=tag>go-micro (1)</a>
<a href=/tags/golang class=tag>golang (1)</a>
<a href=/tags/graceful-shutdown class=tag>graceful-shutdown (1)</a>
<a href=/tags/grafana class=tag>grafana (1)</a>
<a href=/tags/html class=tag>html (1)</a>
<a href=/tags/ide class=tag>ide (1)</a>
<a href=/tags/iframe class=tag>iframe (1)</a>
<a href=/tags/informercat class=tag>informercat (1)</a>
<a href=/tags/insomnia class=tag>insomnia (1)</a>
<a href=/tags/javascript class=tag>javascript (1)</a>
<a href=/tags/json class=tag>json (1)</a>
<a href=/tags/k8s class=tag>k8s (1)</a>
<a href=/tags/launch class=tag>launch (2)</a>
<a href=/tags/life class=tag>life (1)</a>
<a href=/tags/loki class=tag>loki (1)</a>
<a href=/tags/macbook class=tag>macbook (1)</a>
<a href=/tags/macos class=tag>macos (1)</a>
<a href=/tags/microservices class=tag>microservices (1)</a>
<a href=/tags/mongo class=tag>mongo (1)</a>
<a href=/tags/mongodb class=tag>mongodb (2)</a>
<a href=/tags/monitoring class=tag>monitoring (1)</a>
<a href=/tags/nosql class=tag>nosql (1)</a>
<a href=/tags/online class=tag>online (1)</a>
<a href=/tags/pre-processors class=tag>pre-processors (1)</a>
<a href=/tags/prometheus class=tag>prometheus (1)</a>
<a href=/tags/query class=tag>query (1)</a>
<a href=/tags/review class=tag>review (1)</a>
<a href=/tags/s3 class=tag>s3 (1)</a>
<a href=/tags/server class=tag>server (1)</a>
<a href=/tags/ssh class=tag>ssh (1)</a>
<a href=/tags/supics class=tag>supics (1)</a>
<a href=/tags/tailwind class=tag>tailwind (1)</a>
<a href=/tags/tempo class=tag>tempo (1)</a>
<a href=/tags/test class=tag>test (2)</a>
<a href=/tags/tips class=tag>tips (1)</a>
<a href=/tags/tool class=tag>tool (3)</a>
<a href=/tags/vagrant class=tag>vagrant (1)</a>
<a href=/tags/vim class=tag>vim (1)</a>
<a href=/tags/virtualbox class=tag>virtualbox (1)</a>
<a href=/tags/vm class=tag>vm (1)</a>
<a href=/tags/vscode class=tag>vscode (1)</a>
<a href=/tags/vue class=tag>vue (6)</a>
<a href=/tags/vue-cli class=tag>vue-cli (1)</a>
<a href=/tags/webpack class=tag>webpack (2)</a>
<a href=/tags/websocket class=tag>websocket (2)</a>
<a href=/tags/zero-downtime class=tag>zero-downtime (1)</a></div></div></aside></main><footer class=site-footer><div>&copy; 2025 Cozi</div><div>Powered by <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a></div></footer></div><span class=article-tags><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2h10l8.59 8.59a2 2 0 010 2.82z"/><line x1="7" y1="7" x2="7.01" y2="7"/></svg><a href=/tags/monitoring>monitoring</a>
<a href=/tags/distributed-tracing>distributed-tracing</a>
<a href=/tags/grafana>grafana</a>
<a href=/tags/prometheus>prometheus</a>
<a href=/tags/loki>loki</a>
<a href=/tags/tempo>tempo</a></span>
<script async src="https://sdk.owids.com/js/app.js#id=bqnb4q1ba1fujo6isg10"></script></body></html>